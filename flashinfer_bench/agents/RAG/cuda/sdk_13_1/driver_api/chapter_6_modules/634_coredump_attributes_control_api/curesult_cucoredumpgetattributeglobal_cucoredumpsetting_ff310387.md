# CUresult cuCoredumpGetAttributeGlobal (CUcoredumpSettings attrib, void *value, size_t *size)

Allows caller to fetch a coredump attribute value for the entire application.

###### Parameters

**attrib**

  - The enum defining which value to fetch.
**value**

  - void* containing the requested data.
**size**

  - The size of the memory region value points to.

###### Returns

CUDA_SUCCESS, CUDA_ERROR_INVALID_VALUE

###### Description

Returns in *value the requested value specified by attrib. It is up to the caller to ensure that the
data type and size of *value matches the request.

If the caller calls this function with *value equal to NULL, the size of the memory region (in bytes)
expected for attrib will be placed in size.

The supported attributes are:

CU_COREDUMP_ENABLE_ON_EXCEPTION: Bool where true means that GPU exceptions

###### **‣**

from this context will create a coredump at the location specified by CU_COREDUMP_FILE. The
default value is false.
CU_COREDUMP_TRIGGER_HOST: Bool where true means that the host CPU will also create

###### **‣**

a coredump. The default value is true unless set to false globally or or locally. This value is
deprecated as of CUDA 12.5 - raise the CU_COREDUMP_SKIP_ABORT flag to disable host
device abort() if needed.


CUDA Driver API TRM-06703-001 _vRelease Version  |  567


Modules


CU_COREDUMP_LIGHTWEIGHT: Bool where true means that any resulting coredumps will not

###### **‣**

have a dump of GPU memory or non-reloc ELF images. The default value is false. This attribute is
deprecated as of CUDA 12.5, please use CU_COREDUMP_GENERATION_FLAGS instead.
CU_COREDUMP_ENABLE_USER_TRIGGER: Bool where true means that a coredump can be

###### **‣**

created by writing to the system pipe specified by CU_COREDUMP_PIPE. The default value is
false.
CU_COREDUMP_FILE: String of up to 1023 characters that defines the location

###### **‣**

where any coredumps generated by this context will be written. The default value is
core.cuda.HOSTNAME.PID where HOSTNAME is the host name of the machine running the
CUDA applications and PID is the process ID of the CUDA application.
CU_COREDUMP_PIPE: String of up to 1023 characters that defines the name of the

###### **‣**

pipe that will be monitored if user-triggered coredumps are enabled. The default value is
corepipe.cuda.HOSTNAME.PID where HOSTNAME is the host name of the machine running the
CUDA application and PID is the process ID of the CUDA application.
CU_COREDUMP_GENERATION_FLAGS: An integer with values to allow granular

###### **‣**

control the data contained in a coredump specified as a bitwise OR combination of the
following values: + CU_COREDUMP_DEFAULT_FLAGS - if set by itself, coredump
generation returns to its default settings of including all memory regions that it is able
to access + CU_COREDUMP_SKIP_NONRELOCATED_ELF_IMAGES - Coredump
will not include the data from CUDA source modules that are not relocated at runtime. +
CU_COREDUMP_SKIP_GLOBAL_MEMORY - Coredump will not include device-side global
data that does not belong to any context. + CU_COREDUMP_SKIP_SHARED_MEMORY

  - Coredump will not include grid-scale shared memory for the warp that the dumped kernel
belonged to. + CU_COREDUMP_SKIP_LOCAL_MEMORY - Coredump will not include local
memory from the kernel. + CU_COREDUMP_LIGHTWEIGHT_FLAGS - Enables all of the
above options. Equiavlent to setting the CU_COREDUMP_LIGHTWEIGHT attribute to true. +
CU_COREDUMP_SKIP_ABORT - If set, GPU exceptions will not raise an abort() in the host
CPU process. Same functional goal as CU_COREDUMP_TRIGGER_HOST but better reflects the
default behavior.


See also:

cuCoredumpGetAttribute, cuCoredumpSetAttribute, cuCoredumpSetAttributeGlobal
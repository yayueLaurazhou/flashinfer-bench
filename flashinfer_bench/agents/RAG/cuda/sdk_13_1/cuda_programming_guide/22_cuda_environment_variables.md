# 22. CUDA Environment Variables

# 22. CUDA Environment Variables[](#cuda-environment-variables "Permalink to this headline")

Warning

This document has been replaced by a new [CUDA Programming Guide](http://docs.nvidia.com/cuda/cuda-programming-guide). The information in this document should be considered legacy, and this document is no longer being updated as of CUDA 13.0. Please refer to the [CUDA Programming Guide](http://docs.nvidia.com/cuda/cuda-programming-guide) for up-to-date information on CUDA.

The following table lists the CUDA environment variables. Environment variables related to the Multi-Process Service are documented in the Multi-Process Service section of the GPU Deployment and Management guide.

Table 30 CUDA Environment Variables[](#id486 "Permalink to this table")





| Variable | Values | Description |
| --- | --- | --- |
| **Device Enumeration and Properties** |  |  |
| CUDA\_VISIBLE\_DEVICES | A comma-separated sequence of GPU identifiers MIG support: `MIG-<GPU-UUID>/<GPU instance ID>/<compute instance ID>` | GPU identifiers are given as integer indices or as UUID strings. GPU UUID strings should follow the same format as given by *nvidia-smi*, such as GPU-8932f937-d72c-4106-c12f-20bd9faed9f6. However, for convenience, abbreviated forms are allowed; simply specify enough digits from the beginning of the GPU UUID to uniquely identify that GPU in the target system. For example, CUDA\_VISIBLE\_DEVICES=GPU-8932f937 may be a valid way to refer to the above GPU UUID, assuming no other GPU in the system shares this prefix. Only the devices whose index is present in the sequence are visible to CUDA applications and they are enumerated in the order of the sequence. If one of the indices is invalid, only the devices whose index precedes the invalid index are visible to CUDA applications. For example, setting CUDA\_VISIBLE\_DEVICES to 2,1 causes device 0 to be invisible and device 2 to be enumerated before device 1. Setting CUDA\_VISIBLE\_DEVICES to 0,2,-1,1 causes devices 0 and 2 to be visible and device 1 to be invisible. MIG format starts with MIG keyword and GPU UUID should follow the same format as given by *nvidia-smi*. For example, MIG-GPU-8932f937-d72c-4106-c12f-20bd9faed9f6/1/2. Only single MIG instance enumeration is supported. |
| CUDA\_MANAGED\_FORCE\_DEVICE\_ALLOC | 0 or 1 (default is 0) | Forces the driver to place all managed allocations in device memory. |
| CUDA\_DEVICE\_ORDER | FASTEST\_FIRST, PCI\_BUS\_ID, (default is FASTEST\_FIRST) | FASTEST\_FIRST causes CUDA to enumerate the available devices in fastest to slowest order using a simple heuristic. PCI\_BUS\_ID orders devices by PCI bus ID in ascending order. |
| **Compilation** |  |  |
| CUDA\_CACHE\_DISABLE | 0 or 1 (default is 0) | Disables caching (when set to 1) or enables caching (when set to 0) for just-in-time-compilation. When disabled, no binary code is added to or retrieved from the cache. |
| CUDA\_CACHE\_PATH | filepath | Specifies the folder where the just-in-time compiler caches binary codes; the default values are:   * on Windows, `%APPDATA%\NVIDIA\ComputeCache` * on Linux, `~/.nv/ComputeCache` |
| CUDA\_CACHE\_MAXSIZE | integer (default is 1073741824 (1 GiB) for desktop/server platforms and 268435456 (256 MiB) for embedded platforms and the maximum is 4294967296 (4 GiB)) | Specifies the size in bytes of the cache used by the just-in-time compiler. Binary codes whose size exceeds the cache size are not cached. Older binary codes are evicted from the cache to make room for newer binary codes if needed. |
| CUDA\_FORCE\_PTX\_JIT | 0 or 1 (default is 0) | When set to 1, forces the device driver to ignore any binary code embedded in an application (see [Application Compatibility](#application-compatibility)) and to just-in-time compile embedded PTX code instead. If a kernel does not have embedded PTX code, it will fail to load. This environment variable can be used to validate that PTX code is embedded in an application and that its just-in-time compilation works as expected to guarantee application forward compatibility with future architectures (see [Just-in-Time Compilation](#just-in-time-compilation)). |
| CUDA\_DISABLE\_PTX\_JIT | 0 or 1 (default is 0) | When set to 1, disables the just-in-time compilation of embedded PTX code and use the compatible binary code embedded in an application (see [Application Compatibility](#application-compatibility)). If a kernel does not have embedded binary code or the embedded binary was compiled for an incompatible architecture, then it will fail to load. This environment variable can be used to validate that an application has the compatible *SASS* code generated for each kernel.(see [Binary Compatibility](#binary-compatibility)). |
| CUDA\_FORCE\_JIT | 0 or 1 (default is 0) | When set to 1, forces the device driver to ignore any binary code embedded in an application (see [Application Compatibility](#application-compatibility)) and to just-in-time compile embedded PTX code instead. If a kernel does not have embedded PTX code, it will fail to load. This environment variable can be used to validate that PTX code is embedded in an application and that its just-in-time compilation works as expected to guarantee application forward compatibility with future architectures (see [Just-in-Time Compilation](#just-in-time-compilation)). The behavior can be overridden for embedded PTX by setting `CUDA_FORCE_PTX_JIT=0`. |
| CUDA\_DISABLE\_JIT | 0 or 1 (default is 0) | When set to 1, disables the just-in-time compilation of embedded PTX code and use the compatible binary code embedded in an application (see [Application Compatibility](#application-compatibility)). If a kernel does not have embedded binary code or the embedded binary was compiled for an incompatible architecture, then it will fail to load. This environment variable can be used to validate that an application has the compatible SASS code generated for each kernel.(see [Binary Compatibility](#binary-compatibility)). The behavior can be overridden for embedded PTX by setting `CUDA_DISABLE_PTX_JIT=0`. |
| **Execution** |  |  |
| CUDA\_LAUNCH\_BLOCKING | 0 or 1 (default is 0) | Disables (when set to 1) or enables (when set to 0) asynchronous kernel launches. |
| CUDA\_DEVICE\_MAX\_CONNECTIONS | 1 to 32 (default is 8) | Sets the number of compute and copy engine concurrent connections (work queues) from the host to each device of compute capability 3.5 and above. |
| CUDA\_DEVICE\_MAX\_COPY\_CONNECTIONS | 1 to 32 (default is 8) | Sets the number of copy engine concurrent connections (work queues) per async copy engine from the host to each device of compute capability 8.0 and above. When both CUDA\_DEVICE\_MAX\_CONNECTIONS and CUDA\_DEVICE\_MAX\_COPY\_CONNECTIONS are set, only the number of copy connections set by CUDA\_DEVICE\_MAX\_CONNECTIONS will be overwritten. |
| CUDA\_AUTO\_BOOST | 0 or 1 | Overrides the autoboost behavior set by the –auto-boost-default option of nvidia-smi. If an application requests via this environment variable a behavior that is different from nvidia-smi’s, its request is honored if there is no other application currently running on the same GPU that successfully requested a different behavior, otherwise it is ignored. |
| CUDA\_SCALE\_LAUNCH\_QUEUES | “0.25x”, “0.5x”, “2x” or “4x” | Scales the size of the queues available for launching work by a fixed multiplier. |
| CUDA\_DROP\_TO\_IDLE | integer timeout, in milliseconds | On Linux, CUDA normally holds the GPU in a ready state to improve latency. This may lead to higher power use in applications that use the GPU intermittently. When CUDA\_DROP\_TO\_IDLE is set for a process, CUDA contexts in that process will release their hold the specified number of milliseconds after their last GPU operation completes. When all CUDA contexts on the GPU have released their hold, the GPU may reduce its power state. |
| **cuda-gdb (on Linux platform)** |  |  |
| CUDA\_DEVICE\_WAITS\_ON\_EXCEPTION | 0 or 1 (default is 0) | When set to 1, a CUDA application will halt when a device exception occurs, allowing a debugger to be attached for further debugging. |
| **MPS service (on Linux platform)** |  |  |
| CUDA\_DEVICE\_DEFAULT\_PERSISTING\_L2\_CACHE\_PERCENTAGE\_LIMIT | Percentage value (between 0 - 100, default is 0) | Devices of compute capability 8.x allow, a portion of L2 cache to be set-aside for persisting data accesses to global memory. When using CUDA MPS service, the set-aside size can only be controlled using this environment variable, before starting CUDA MPS control daemon. I.e., the environment variable should be set before running the command `nvidia-cuda-mps-control -d`. |
| **Module loading** |  |  |
| CUDA\_MODULE\_LOADING | DEFAULT, LAZY, EAGER (default is LAZY) | Specifies the module loading mode for the application. When set to EAGER, all kernels and data from a cubin, fatbin or a PTX file are fully loaded upon corresponding `cuModuleLoad*` and `cuLibraryLoad*` API call. When set to LAZY, loading of specific kernels is delayed to the point a CUfunc handle is extracted with `cuModuleGetFunction` or `cuKernelGetFunction` API calls and data from the cubin is loaded at load of first kernel in the cubin or at first access of variables in the cubin. Default behavior may change in future CUDA releases. |
| CUDA\_MODULE\_DATA\_LOADING | DEFAULT, LAZY, EAGER (default is LAZY) | Specifies the data loading mode for the application. When set to EAGER, all data from a cubin, fatbin or a PTX file are fully loaded to memory upon corresponding `cuLibraryLoad*`. This doesn’t affect the LAZY or EAGER loading of kernels. When set to LAZY, loading of data is delayed to the point at which a handle is required. Default behavior may change in future CUDA releases. Data loading behavior is inherited from `CUDA_MODULE_LOADING` if this environment variable is not set. |
| **Pre-loading dependent libraries** |  |  |
| CUDA\_FORCE\_PRELOAD\_LIBRARIES | 0 or 1 (default is 0) | When set to 1, forces the driver to preload the libraries required for NVVM and PTX just-in-time compilation during driver initialization. This will increase the memory footprint and the time taken for CUDA driver initialization. This environment variable needs to be set to avoid certain deadlock situations involving multiple CUDA threads. |
| **CUDA Graphs** |  |  |
| CUDA\_GRAPHS\_USE\_NODE\_PRIORITY | 0 or 1 | Overrides the cudaGraphInstantiateFlagUseNodePriority flag on graph instantiation. When set to 1, the flag will be set for all graphs and when set to 0, the flag will be cleared for all graphs. |
| **CUDA Error Log Management** |  |  |
| CUDA\_LOG\_FILE | stdout, stderr, or valid file path | Provides a location for printing error logs as they occur. See the `Error Log Management` section for more details. |
# 5.1.7. Shared State Space

### 5.1.7. [Shared State Space](https://docs.nvidia.com/cuda/parallel-thread-execution/#shared-state-space)[ÔÉÅ](https://docs.nvidia.com/cuda/parallel-thread-execution/#shared-state-space "Permalink to this headline")

The shared (`.shared`) state space is a memory that is owned by an executing CTA and is accessible
to the threads of all the CTAs within a cluster. An address in shared memory can be read and written
by any thread in a CTA cluster.

Additional sub-qualifiers `::cta` or `::cluster` can be specified on instructions with
`.shared` state space to indicate whether the address belongs to the shared memory window of the
executing CTA or of any CTA in the cluster respectively. The addresses in the `.shared::cta`
window also fall within the `.shared::cluster` window. If no sub-qualifier is specified with the
`.shared` state space, then it defaults to `::cta`. For example, `ld.shared` is equivalent to
`ld.shared::cta`.

Variables declared in `.shared` state space refer to the memory addresses in the current
CTA. Instruction `mapa` gives the `.shared::cluster` address of the corresponding variable in
another CTA in the cluster.

Shared memory typically has some optimizations to support the sharing. One example is broadcast;
where all threads read from the same address. Another is sequential access from sequential threads.
# 2.2.2. Cluster of Cooperative Thread Arrays

### 2.2.2. [Cluster of Cooperative Thread Arrays](https://docs.nvidia.com/cuda/parallel-thread-execution/#cluster-of-cooperative-thread-arrays)[](https://docs.nvidia.com/cuda/parallel-thread-execution/#cluster-of-cooperative-thread-arrays "Permalink to this headline")

Cluster is a group of CTAs that run concurrently or in parallel and can synchronize and communicate
with each other via shared memory. The executing CTA has to make sure that the shared memory of the
peer CTA exists before communicating with it via shared memory and the peer CTA hasn’t exited before
completing the shared memory operation.

Threads within the different CTAs in a cluster can synchronize and communicate with each other via
shared memory. Cluster-wide barriers can be used to synchronize all the threads within the
cluster. Each CTA in a cluster has a unique CTA identifier within its cluster
(*cluster\_ctaid*). Each cluster of CTAs has 1D, 2D or 3D shape specified by the parameter
*cluster\_nctaid*. Each CTA in the cluster also has a unique CTA identifier (*cluster\_ctarank*)
across all dimensions. The total number of CTAs across all the dimensions in the cluster is
specified by *cluster\_nctarank*. Threads may read and use these values through predefined, read-only
special registers `%cluster_ctaid`, `%cluster_nctaid`, `%cluster_ctarank`,
`%cluster_nctarank`.

Cluster level is applicable only on target architecture `sm_90` or higher. Specifying cluster
level during launch time is optional. If the user specifies the cluster dimensions at launch time
then it will be treated as explicit cluster launch, otherwise it will be treated as implicit cluster
launch with default dimension 1x1x1. PTX provides read-only special register
`%is_explicit_cluster` to differentiate between explicit and implicit cluster launch.
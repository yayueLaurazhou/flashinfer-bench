{
  "description": "Documentation for 9.7.16.10.5. Data Path Layout Organization",
  "directories": [],
  "files": [
    {
      "id": "overview",
      "title": "Overview",
      "filename": "overview.md",
      "tags": [
        "overview"
      ],
      "summary": "Different MMA variants access the tensor memory with different layout organization. The following table lists the various layouts:"
    },
    {
      "id": "97161051_layout_a_m_256",
      "title": "9.7.16.10.5.1. Layout A (M = 256)",
      "tags": [
        "ptx",
        "documentation"
      ],
      "summary": "Layout organization for M = 256 is shown in [Figure 205](https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-data-path-layout-a1).",
      "filename": "97161051_layout_a_m_256.md"
    },
    {
      "id": "97161052_layout_b_m_128_cta_group2_dense_a_matrix",
      "title": "9.7.16.10.5.2. Layout B (M = 128 + cta-group::2 + Dense A matrix)",
      "tags": [
        "ptx",
        "documentation"
      ],
      "summary": "Layout organization for M = 128 + .cta\\_group::2 + Dense A matrix is shown in [Figure 207](https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-data-path-layout-b1).",
      "filename": "97161052_layout_b_m_128_cta_group2_dense_a_matrix.md"
    },
    {
      "id": "97161053_layout_c_m_128_cta_group2_sparse_a_matrix",
      "title": "9.7.16.10.5.3. Layout C (M = 128 + cta-group::2 + Sparse A matrix)",
      "tags": [
        "ptx",
        "documentation"
      ],
      "summary": "Layout organization for M = 128 + .cta\\_group::2 + Sparse A matrix is shown in [Figure 209](https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-data-path-layout-c1).",
      "filename": "97161053_layout_c_m_128_cta_group2_sparse_a_matrix.md"
    },
    {
      "id": "97161054_layout_d_m_128_cta_group1",
      "title": "9.7.16.10.5.4. Layout D (M = 128 + cta-group::1)",
      "tags": [
        "ptx",
        "documentation"
      ],
      "summary": "Layout organization for M = 128 + .cta\\_group::1 is shown in [Figure 211](https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-data-path-layout-d1).",
      "filename": "97161054_layout_d_m_128_cta_group1.md"
    },
    {
      "id": "97161055_layout_e_m_64_ws_mode",
      "title": "9.7.16.10.5.5. Layout E (M = 64 + .ws mode)",
      "tags": [
        "ptx",
        "documentation"
      ],
      "summary": "Layout organization for M = 64 + .ws mode is shown in [Figure 213](https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-data-path-layout-e1).",
      "filename": "97161055_layout_e_m_64_ws_mode.md"
    },
    {
      "id": "97161056_layout_f_m_64_non_ws_mode",
      "title": "9.7.16.10.5.6. Layout F (M = 64 + non .ws mode)",
      "tags": [
        "ptx",
        "documentation"
      ],
      "summary": "Layout organization for M = 64 + non .ws mode is shown in [Figure 215](https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-data-path-layout-f1).",
      "filename": "97161056_layout_f_m_64_non_ws_mode.md"
    },
    {
      "id": "97161057_layout_g_m_32",
      "title": "9.7.16.10.5.7. Layout G (M = 32)",
      "tags": [
        "ptx",
        "documentation"
      ],
      "summary": "Layout organization for M = 32 is shown in [Figure 217](https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-data-path-layout-g1).",
      "filename": "97161057_layout_g_m_32.md"
    }
  ]
}
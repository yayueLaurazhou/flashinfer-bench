# 9.7.9. Data Movement and Conversion Instructions

### 9.7.9. [Data Movement and Conversion Instructions](https://docs.nvidia.com/cuda/parallel-thread-execution/#data-movement-and-conversion-instructions)[ÔÉÅ](https://docs.nvidia.com/cuda/parallel-thread-execution/#data-movement-and-conversion-instructions "Permalink to this headline")

These instructions copy data from place to place, and from state space to state space, possibly
converting it from one format to another. `mov`, `ld`, `ldu`, and `st` operate on both
scalar and vector types. The `isspacep` instruction is provided to query whether a generic address
falls within a particular state space window. The `cvta` instruction converts addresses between
`generic` and `const`, `global`, `local`, or `shared` state spaces.

Instructions `ld`, `st`, `suld`, and `sust` support optional cache operations.

The Data Movement and Conversion Instructions are:

* `mov`
* `shfl.sync`
* `prmt`
* `ld`
* `ldu`
* `st`
* `st.async`
* `st.bulk`
* `multimem.ld_reduce`, `multimem.st`, `multimem.red`
* `prefetch`, `prefetchu`
* `isspacep`
* `cvta`
* `cvt`
* `cvt.pack`
* `cp.async`
* `cp.async.commit_group`
* `cp.async.wait_group`, `cp.async.wait_all`
* `cp.async.bulk`
* `cp.reduce.async.bulk`
* `cp.async.bulk.prefetch`
* `multimem.cp.async.bulk`
* `multimem.cp.reduce.async.bulk`
* `cp.async.bulk.tensor`
* `cp.reduce.async.bulk.tensor`
* `cp.async.bulk.prefetch.tensor`
* `cp.async.bulk.commit_group`
* `cp.async.bulk.wait_group`
* `tensormap.replace`
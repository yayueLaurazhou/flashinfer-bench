# 9.7.5.3. Mixed Precision Floating Point Instructions: fma

#### 9.7.5.3. [Mixed Precision Floating Point Instructions: `fma`](https://docs.nvidia.com/cuda/parallel-thread-execution/#mixed-precision-floating-point-instructions-fma)[ÔÉÅ](https://docs.nvidia.com/cuda/parallel-thread-execution/#mixed-precision-floating-point-instructions-fma "Permalink to this headline")

`fma`

Fused multiply-add.

Syntax

```
fma.rnd{.sat}.f32.abtype  d, a, b, c;

.abtype = { .f16, .bf16};
.rnd    = { .rn, .rz, .rm, .rp };
```

Copy to clipboard

Description

Converts input operands `a` and `b` from `.atype` into `.f32` type. The converted values
are then used to perform fused multiply-add operation with no loss of precision in the intermediate
product and addition. The resulting value is stored in the destination operand `d`.

Semantics

```
d = convert(a) * convert(b) + c;
```

Copy to clipboard

Notes

`fma.f32.{f16/bf16}` computes the product of `a` and `b` to infinite precision and then adds
`c` to this product, again in infinite precision. The resulting value is then rounded to single
precision using the rounding mode specified by `.rnd`.

Rounding modifiers(no default):

`.rn`
:   mantissa LSB rounds to nearest even

`.rz`
:   mantissa LSB rounds towards zero

`.rm`
:   mantissa LSB rounds towards negative infinity

`.rp`
:   mantissa LSB rounds towards positive infinity

Subnormal numbers:
:   By default, subnormal numbers are supported.

Saturation modifier:
:   `fma.sat` clamps the result to [0.0, 1.0]. `NaN` results are flushed to `+0.0f`.

PTX ISA Notes

`fma.f32.{f16/bf16}` introduced in PTX ISA version 8.6.

Target ISA Notes

`fma.f32.{f16/bf16}` requires `sm_100` or higher.

Examples

```
.reg .f32 fc, fd;
.reg .f16 ha, hb;
fma.rz.sat.f32.f16.sat   fd, ha, hb, fc;
```

Copy to clipboard
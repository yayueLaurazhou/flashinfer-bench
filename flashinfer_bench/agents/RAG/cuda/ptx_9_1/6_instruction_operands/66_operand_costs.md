# 6.6. Operand Costs

## 6.6. [Operand Costs](https://docs.nvidia.com/cuda/parallel-thread-execution/#operand-costs)[](https://docs.nvidia.com/cuda/parallel-thread-execution/#operand-costs "Permalink to this headline")

Operands from different state spaces affect the speed of an operation. Registers are fastest, while
global memory is slowest. Much of the delay to memory can be hidden in a number of ways. The first
is to have multiple threads of execution so that the hardware can issue a memory operation and then
switch to other execution. Another way to hide latency is to issue the load instructions as early as
possible, as execution is not blocked until the desired result is used in a subsequent (in time)
instruction. The register in a store operation is available much more
quickly. [Table 19](https://docs.nvidia.com/cuda/parallel-thread-execution/#operand-costs-cost-estimates-for-sccessing-state-spaces) gives estimates of the
costs of using different kinds of memory.

Table 19 Cost Estimates for Accessing State-Spaces[](https://docs.nvidia.com/cuda/parallel-thread-execution/#operand-costs-cost-estimates-for-sccessing-state-spaces "Permalink to this table")





| Space | Time | Notes |
| --- | --- | --- |
| Register | 0 |  |
| Shared | 0 |  |
| Constant | 0 | Amortized cost is low, first access is high |
| Local | > 100 clocks |  |
| Parameter | 0 |  |
| Immediate | 0 |  |
| Global | > 100 clocks |  |
| Texture | > 100 clocks |  |
| Surface | > 100 clocks |  |